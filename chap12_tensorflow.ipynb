{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 텐서 = 배열(Array)\n",
    "* Rank\n",
    "\n",
    "몇 차원 배열인가를 의미\n",
    "|Rank   |Math Entity                        |Example                                                    |\n",
    "|-------|-------------------------------    |----------                                                 |\n",
    "|0      |Scalar(magnitude only)             |s = 483                                                    |\n",
    "|1      |Vector(magnitude and direction)    |v = [1.1, 2.2, 3.3]                                        |\n",
    "|2      |Maxrix(table of numbers)           |m = [[1, 2, 3], [1, 2, 3], [1, 2, 3]]                      |\n",
    "|3      |3-Tensor(cube of numbers)          |c = [[[1], [2], [3]], [[4], [5], [6]], [[7], [8], [9]]]    |\n",
    "|n      |n-Tensor(n 차원 배열)              |...                                                        |\n",
    "\n",
    "스칼라(Scalar)는 0차원 배열\n",
    "rank가 n이면 n차원 배열\n",
    "\n",
    "* 텐서의 Shape\n",
    "\n",
    "각 축이 몇 개의 엘리먼트(Element)들로 구성되었는지 나타내는 값.\n",
    "shape = (2, 3) 2행 3열\n",
    "\n",
    "* 텐서의 Type\n",
    "\n",
    "텐서가 담을 수 있는 데이터의 타입을 의미. tf.float32, tf.int32 등\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.constant([[1., 2., 3.], [4., 5., 6.]]) #행렬 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = tf.constant(42) #스칼라 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(TensorShape([2, 3]), tf.float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.shape, t.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2. 3.]\n",
      " [5. 6.]], shape=(2, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 1), dtype=float32, numpy=\n",
       "array([[2.],\n",
       "       [5.]], dtype=float32)>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t[:, 1:])\n",
    "t[..., 1, tf.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[11. 12. 13.]\n",
      " [14. 15. 16.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]], shape=(2, 3), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[1. 4.]\n",
      " [2. 5.]\n",
      " [3. 6.]], shape=(3, 2), dtype=float32)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[14., 32.],\n",
       "       [32., 77.]], dtype=float32)>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(t + 10)\n",
    "print(tf.square(t))\n",
    "print(tf.transpose(t))\n",
    "t @ tf.transpose(t) # @: matmul"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 2 텐서와 넘파이\n",
    "numpy는 기본적으로 64비트 정밀도 사용\n",
    "tensorflow는 32비트 사용\n",
    "왜냐하면 신경망은 32비트로도 충분, 더 빠름, 메모리도 적게 사용\n",
    "넘파이 배열로 텐서를 만들 때 dtype=tf.float32로 지정해야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 4. 5.], shape=(3,), dtype=float64)\n",
      "[[1. 2. 3.]\n",
      " [4. 5. 6.]]\n",
      "tf.Tensor([ 4. 16. 25.], shape=(3,), dtype=float64)\n",
      "[[ 1.  4.  9.]\n",
      " [16. 25. 36.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([2., 4., 5.])\n",
    "print(tf.constant(a)) #numpy 행렬로 텐서 생성\n",
    "print(t.numpy()) # 또는 np.array(t)\n",
    "print(tf.square(a))\n",
    "print(np.square(t))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 3 타입 변환\n",
    "타입변환은 성능을 크게 감소시킬 수 있음\n",
    "자동 타입 변환을 방지하기 위해 tensorflow는 자동으로 타입 변환시키지 않음\n",
    "호환되지 않는 타입의 텐서로 연산 실행하면 예외 발생\n",
    "\"정수 + 실수 텐서\"x, \"32비트 실수\" + \"64비트 실수\"x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-b39adccd9984>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print(tf.constant(2.) + tf.constant(40)) 오류 발생\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2.\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m40.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\PiusHwang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 153\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    155\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\PiusHwang\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mraise_from_not_ok_status\u001b[1;34m(e, name)\u001b[0m\n\u001b[0;32m   7162\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7163\u001b[0m   \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\" name: \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 7164\u001b[1;33m   \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: cannot compute AddV2 as input #1(zero-based) was expected to be a float tensor but is a double tensor [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "# print(tf.constant(2.) + tf.constant(40)) 오류 발생\n",
    "# print(tf.constant(2.) + tf.constant(40., dtype=tf.float64))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 4 변수\n",
    "위의 Tensor는 변경이 불가능한 객체. 즉 텐서의 내용을 변경할 수 없음\n",
    "따라서 일반적인 텐서로는 역전파로 변경되어야하는 신경망의 **가중치**를 구현 불가능\n",
    "또한 시간에 따라 변경되어야 할 파라미터도 있음(e.g. 모멘텀 옵티마이저는 과거 gradient를 계속 업데이트)\n",
    "이떄 **tf.Variable** 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'Variable:0' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[1., 2., 3.],\n",
       "       [4., 5., 6.]], dtype=float32)>"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v = tf.Variable([[1., 2., 3.], [4., 5., 6.]])\n",
    "v"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.Variable은 tf.Tensor와 비슷하게 동작함\n",
    "다른 점은 **assign()** 메서드를 사용하여 개별 원소 변경 가능\n",
    "**scatter_update(), scatter_nd_update()** 메서드를 사용하여 개별 원소(또는 슬라이스)를 수정 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 2.,  4.,  6.],\n",
      "       [ 8., 10., 12.]], dtype=float32)>\n",
      "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 2., 42.,  6.],\n",
      "       [ 8., 10., 12.]], dtype=float32)>\n",
      "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
      "array([[ 2., 42.,  0.],\n",
      "       [ 8., 10.,  1.]], dtype=float32)>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=(2, 3) dtype=float32, numpy=\n",
       "array([[100.,  42.,   0.],\n",
       "       [  8.,  10., 200.]], dtype=float32)>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(v.assign(2 * v)) # => [[2., 4., 6.], [8., 10., 12]]\n",
    "print(v[0, 1].assign(42)) # [0, 1] 변수를 42로 변경\n",
    "print(v[:, 2].assign([0., 1.])) # 2열 각각을 0.과 1.으로 변경\n",
    "v.scatter_nd_update(indices=[[0, 0], [1, 2]], updates=[100., 200.])\n",
    "# [0, 0] 원소와 [1, 2] 원소를 각각 100.과 200.로 변경"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 2.5 다른 데이터 구조\n",
    "* 희소 텐서(sparse tensor, tf.SparseTensor)\n",
    "tf.sparse패키지는 희소 텐서를 위한 연산 제공\n",
    "* 텐서 배열(tensor array, tf.TensorArray)\n",
    "텐서의 리스트. 길이 동적 변경 가능. \n",
    "리스트 내의 모든 텐서는 동일한 크기와 타입이어야 함\n",
    "* 래그드 텐서(ragged tensor, tf.RaggedTensor)\n",
    "리스트의 리스트를 나타냄. 동일한 데이터 타입, 길이는 다를 수 있음\n",
    "* 문자열 텐서(string tensor)\n",
    "tf.string 타입의 텐서. \n",
    "* 집합(set)\n",
    "일반적인 텐서로 나타냄. tf.constant()\n",
    "* 큐(queue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 3 사용자 정의 모델과 훈련 알고리즘\n",
    "\n",
    "12. 3.1 사용자 정의 손실함수\n",
    "regression model을 훈련하는 데 훈련 세트에 잡음 데이터가 조금 있다고 가정하면 huber 사용(keras.losses.Huber 도 있음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def huber_fn(y_true, y_pred):\n",
    "    error = y_true - y_pred\n",
    "    is_small_error = tf.abs(error) < 1\n",
    "    squared_loss = tf.square(error) /2\n",
    "    linear_loss = tf.abs(error) - 0.5\n",
    "    return tf.where(is_small_error, squared_loss, linear_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. 3.2 사용자 정의 요소를 가진 모델을 저장 & 로드하기\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(0.0050000004, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "70c70cd075dd7b9e0853a7ccfb5afa16778087645abdf90ca4241a88501a1ac5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
